{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206f5d8c",
   "metadata": {},
   "source": [
    "# 효율적인 정리를 위한 class화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb478656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.wcdjnk7yvmpzq2me2zzhjjrj3jikndb7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            learning_rate = 0.01\n",
    "            keep_prob = 0.7\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            # Convolution layer1\n",
    "            W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides = [1,2,2,1], padding=\"SAME\")\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "            # Convolution layer2\n",
    "            W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides = [1,2,2,1], padding=\"SAME\")\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "            # Convolution layer3\n",
    "            W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides = [1,2,2,1], padding=\"SAME\")\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "            L3 = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            #FC layer\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer= tf.compat.v1.keras.initializers.glorot_normal)\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.compat.v1.keras.initializers.glorot_normal)\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            hypothesis = tf.matmul(L4, W5) + b5\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=self.Y))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "            correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(self.Y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#     def predict(self, x_test, keep_prop=1.0):\n",
    "#         return self.sess.run(self.logits, feed_dict = {self.X: x_test,  keep_prob: keep_prop})\n",
    "    \n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        (X_test, y_test), (X_test, y_test) = mnist.load_data()\n",
    "        input_shape = X_test.shape[1] * X_test.shape[2]\n",
    "        nb_classes = 10\n",
    "        X_test = X_test.reshape(-1, input_shape) \n",
    "        y_test = to_categorical(y_test, nb_classes)\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: X_test, self.Y: y_test,  keep_prob: keep_prop})\n",
    "    \n",
    "    def train(self, X_data, y_data, keep_prob=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: X_data, self.Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcc7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67daa8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(-1, input_shape) \n",
    "y_train = to_categorical(y_train, nb_classes)\n",
    "X_train = tf.image.convert_image_dtype(X_train, tf.float32)\n",
    "y_train = tf.image.convert_image_dtype(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ccf114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Learning strated!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "m1 = Model(sess, \"m1\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Learning strated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2defc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b2127",
   "metadata": {},
   "source": [
    "# 일반 epoch 구조로 모델 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0516e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:59<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.586594294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:02<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 cost = 0.337489042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:56<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 cost = 0.309279121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 410/600 [03:59<01:57,  1.62it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(60000/ batch_size)\n",
    "    for i in tqdm(range(total_batch)):\n",
    "        batch_xs, batch_ys = X_train[(i*batch_size):batch_size+(i*batch_size)].eval(), y_train[(i*batch_size):batch_size+(i*batch_size)].eval()\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "    print(\"Epoch:\", \"%04d\" % (epoch + 1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "print(\"Leraning Finished!\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32361d",
   "metadata": {},
   "source": [
    "# ensemble 구조로 model 돌리기\n",
    "- num_models: model를 여러번 학습하는 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aca3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "models = []\n",
    "num_models = 7\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\"+ str(m)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Learning Started!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e79164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(60000/ batch_size)\n",
    "    for i in tqdm(range(total_batch)):\n",
    "        batch_xs, batch_ys = X_train[(i*batch_size):batch_size+(i*batch_size)].eval(), y_train[(i*batch_size):batch_size+(i*batch_size)].eval()\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "    print(\"Epoch:\", \"%04d\"%(epoch + 1), 'cost =', avg_cost_list)\n",
    "print(\"Learning Finished!\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3efa67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

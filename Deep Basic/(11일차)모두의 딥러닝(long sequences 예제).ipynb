{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0eee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"if you want you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed55f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12835c1d",
   "metadata": {},
   "source": [
    "###### list(set()) -> 안의 값을 나열(set)한 뒤 list로 인덱싱해주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = list(set(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ce8d5",
   "metadata": {},
   "source": [
    "###### {c: i for i, c in enumerate(idx2char)} -> 각각의 값을 dict하여 key와 value로 나누주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11091f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c: i for i, c in enumerate(idx2char)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208c642",
   "metadata": {},
   "source": [
    "###### x값과 y 값을 인덱스 하나 차이로 두는 이유는 연속적인 단어이기 때문에 이전의 값을 토대로 예측이 필요한 구성이기 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = [char2idx[c] for c in sample]\n",
    "x_data = [sample_idx[:-1]]\n",
    "y_data = [sample_idx[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6362b",
   "metadata": {},
   "source": [
    "# 자동으로 원하는 크기 출력\n",
    "- dic_size -> input size\n",
    "- rnn_hidden_size = RNN output size\n",
    "- num_classes = output size\n",
    "- sequence_length = y_data = [sample_idx[1:]]을 가지므로 -1를 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94083573",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size = len(char2idx)\n",
    "rnn_hidden_size = len(char2idx)\n",
    "num_classes = len(char2idx)\n",
    "batch_size = 1\n",
    "sequence_length = len(sample) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bcf5cf",
   "metadata": {},
   "source": [
    "###### tf.one_hot를 하면 num_classes만큼 one hot encoding 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b656a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = tf.one_hot(X, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1f640",
   "metadata": {},
   "source": [
    "# tf.compat.v1.nn.dynamic_rnn에서 값 제한\n",
    "- intial_state를 통해 모든 값을 기본화\n",
    "- intial_state 대신에 sequence_length = [a,b,c]와 같이 원하는 값을 넣으면\n",
    "- hidden layer층을 지나면서 각각 a, b, c 값을 제외하고 나머지 loss 값 계산을 하지 않아 원하는 loss 값 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tfa.seq2seq.sequence_loss(logits=outputs, targets=Y,weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dddd03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    l, _ = sess.run([loss, train], feed_dict={X: x_data, Y: y_data})\n",
    "    result = sess.run(prediction, feed_dict={X: x_data})\n",
    "    result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "    print(i, \"loss: \", l, \"prediction\", ''.join(result_str))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916dff3",
   "metadata": {},
   "source": [
    "# 심화 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e74f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\since\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b766920",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =(\"if you want to build a ship, dont't drum up people together tocollect wood and don't assign them tasks and work,\"\n",
    "         \" but rather teach them to long for the endless immensity of the sea.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c921623",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7d5dd",
   "metadata": {},
   "source": [
    "###### seq_length = 뽑아내고 싶은 단어의 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0aef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, dont\n",
      "23 ship, dont -> hip, dont'\n",
      "24 hip, dont' -> ip, dont't\n",
      "25 ip, dont't -> p, dont't \n",
      "26 p, dont't  -> , dont't d\n",
      "27 , dont't d ->  dont't dr\n",
      "28  dont't dr -> dont't dru\n",
      "29 dont't dru -> ont't drum\n",
      "30 ont't drum -> nt't drum \n",
      "31 nt't drum  -> t't drum u\n",
      "32 t't drum u -> 't drum up\n",
      "33 't drum up -> t drum up \n",
      "34 t drum up  ->  drum up p\n",
      "35  drum up p -> drum up pe\n",
      "36 drum up pe -> rum up peo\n",
      "37 rum up peo -> um up peop\n",
      "38 um up peop -> m up peopl\n",
      "39 m up peopl ->  up people\n",
      "40  up people -> up people \n",
      "41 up people  -> p people t\n",
      "42 p people t ->  people to\n",
      "43  people to -> people tog\n",
      "44 people tog -> eople toge\n",
      "45 eople toge -> ople toget\n",
      "46 ople toget -> ple togeth\n",
      "47 ple togeth -> le togethe\n",
      "48 le togethe -> e together\n",
      "49 e together ->  together \n",
      "50  together  -> together t\n",
      "51 together t -> ogether to\n",
      "52 ogether to -> gether toc\n",
      "53 gether toc -> ether toco\n",
      "54 ether toco -> ther tocol\n",
      "55 ther tocol -> her tocoll\n",
      "56 her tocoll -> er tocolle\n",
      "57 er tocolle -> r tocollec\n",
      "58 r tocollec ->  tocollect\n",
      "59  tocollect -> tocollect \n",
      "60 tocollect  -> ocollect w\n",
      "61 ocollect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "dataX = []\n",
    "datay = []\n",
    "for i in range(0, len(sentence) - seq_length):\n",
    "    x_str = sentence[i:i + seq_length]\n",
    "    y_str = sentence[i + 1:i + seq_length + 1]\n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    dataX.append(x)\n",
    "    datay.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced6b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffc9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "seq_length = seq_length\n",
    "batch_size = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc4ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, seq_length])\n",
    "Y = tf.placeholder(tf.int32, [None, seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88f6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = tf.one_hot(X, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3032fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\since\\anaconda3\\lib\\site-packages\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:699: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n"
     ]
    }
   ],
   "source": [
    "cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units = hidden_size, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202c3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\since\\AppData\\Local\\Temp/ipykernel_4744/1064150691.py:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\since\\anaconda3\\lib\\site-packages\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:750: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\since\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state, ,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3516710",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f86797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, seq_length])\n",
    "sequence_loss = tfa.seq2seq.sequence_loss(logits=outputs, targets=Y,weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0247f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe4b09",
   "metadata": {},
   "source": [
    "# 오류가 나는 이유? \n",
    "- logits 부분에서 활성함수를 거친 output 값을 넣어주기 때문에 오류가 나므로 활성함수를 거치지 않은 output 값을 넣어주면 됨\n",
    "- 뒤 부분은 새로운 장에 다시 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae5da960",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: assertion failed: [Expected shape for Tensor rnn/sequence_length:0 is ] [170] [ but saw shape: ] [1]\n\t [[node rnn/Assert/Assert (defined at \\AppData\\Local\\Temp/ipykernel_4744/1064150691.py:2) ]]\n  (1) Invalid argument: assertion failed: [Expected shape for Tensor rnn/sequence_length:0 is ] [170] [ but saw shape: ] [1]\n\t [[node rnn/Assert/Assert (defined at \\AppData\\Local\\Temp/ipykernel_4744/1064150691.py:2) ]]\n\t [[Mean/_25]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'rnn/Assert/Assert':\n  File \"\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n    result = self._run_cell(\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"\\AppData\\Local\\Temp/ipykernel_4744/1064150691.py\", line 2, in <module>\n    outputs, _states = tf.nn.dynamic_rnn(cell, x_one_hot, sequence_length=[10] ,dtype=tf.float32)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 346, in new_func\n    return func(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 678, in dynamic_rnn\n    [_assert_has_shape(sequence_length, [batch_size])]):\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 669, in _assert_has_shape\n    return control_flow_ops.Assert(\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs),\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 173, in Assert\n    return gen_logging_ops._assert(condition, data, summarize, name=\"Assert\")\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 60, in _assert\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: assertion failed: [Expected shape for Tensor rnn/sequence_length:0 is ] [170] [ but saw shape: ] [1]\n\t [[{{node rnn/Assert/Assert}}]]\n  (1) Invalid argument: assertion failed: [Expected shape for Tensor rnn/sequence_length:0 is ] [170] [ but saw shape: ] [1]\n\t [[{{node rnn/Assert/Assert}}]]\n\t [[Mean/_25]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4744/629310934.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdataX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatay\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdataX\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresult_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"loss: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: assertion failed: [Expected shape for Tensor rnn/sequence_length:0 is ] [170] [ but saw shape: ] [1]\n\t [[node rnn/Assert/Assert (defined at \\AppData\\Local\\Temp/ipykernel_4744/1064150691.py:2) ]]\n  (1) Invalid argument: assertion failed: [Expected shape for Tensor rnn/sequence_length:0 is ] [170] [ but saw shape: ] [1]\n\t [[node rnn/Assert/Assert (defined at \\AppData\\Local\\Temp/ipykernel_4744/1064150691.py:2) ]]\n\t [[Mean/_25]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'rnn/Assert/Assert':\n  File \"\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n    app.start()\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n    result = self._run_cell(\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"\\AppData\\Local\\Temp/ipykernel_4744/1064150691.py\", line 2, in <module>\n    outputs, _states = tf.nn.dynamic_rnn(cell, x_one_hot, sequence_length=[10] ,dtype=tf.float32)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 346, in new_func\n    return func(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 678, in dynamic_rnn\n    [_assert_has_shape(sequence_length, [batch_size])]):\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 669, in _assert_has_shape\n    return control_flow_ops.Assert(\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs),\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 173, in Assert\n    return gen_logging_ops._assert(condition, data, summarize, name=\"Assert\")\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 60, in _assert\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    l, _ = sess.run([loss, train], feed_dict={X: dataX, Y: datay})\n",
    "    result = sess.run(prediction, feed_dict={X:dataX})\n",
    "    result_str = [char_set[c] for c in np.squeeze(result)]\n",
    "    print(i, \"loss: \", l, \"prediction\", ''.join(result_str))\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

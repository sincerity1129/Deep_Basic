{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babc1b1a",
   "metadata": {},
   "source": [
    "# Neural Network(미분의 chain rule 이해하기 - Back propagation)\n",
    "- f = wx +b -> f(x) = w - 이유? x의 값을 중심으로 보기 때문에 af/ax가 되어 x는 1이 되고 w는 상수가 되어 1*w가 됨\n",
    "- g = wx , f = g+b -> f(g(x) = w - 이유? (af/ag)*(ag/ax)에서 af/ag = 1되고 ag/ax하면 w 값만 남게 되어 결구 1*w가됨\n",
    "- 복잡한 layer층의 경우 최종 layer층의 미분을 구한 이전 local layer층의 미분을 구해 (최종 미분)*(local 미분)의 값을 구하면 됨\n",
    "- 이와 같은 방식으로 input layer층까지 동일한 방식으로 하여 미분을 구함 // (input local 미분)*(local 미분)*....*(최종 미분)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f41085",
   "metadata": {},
   "source": [
    "### hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b)\n",
    "- 자세한 내용 3일차 binary 함수 부분 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7cc71",
   "metadata": {},
   "source": [
    "### cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "- 자세한 내용 3일차 binary 함수 부분 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaeac16",
   "metadata": {},
   "source": [
    "# Neural Network 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb1e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\since\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd37a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07fdbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167717c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3497d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10107ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7f4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478fe4a0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.85533464 [[ 0.0651253]\n",
      " [-1.6997292]]\n",
      "100 0.7147639 [[ 0.15983139]\n",
      " [-0.8159518 ]]\n",
      "200 0.7005834 [[ 0.0456118 ]\n",
      " [-0.47953805]]\n",
      "300 0.6958179 [[-0.00605738]\n",
      " [-0.28722998]]\n",
      "400 0.6941557 [[-0.02390527]\n",
      " [-0.17421266]]\n",
      "500 0.6935469 [[-0.02672737]\n",
      " [-0.10704004]]\n",
      "600 0.69331217 [[-0.0236971 ]\n",
      " [-0.06660391]]\n",
      "700 0.69321746 [[-0.01901593]\n",
      " [-0.04193776]]\n",
      "800 0.6931778 [[-0.01444874]\n",
      " [-0.02669396]]\n",
      "900 0.6931608 [[-0.01061432]\n",
      " [-0.01715589]]\n",
      "1000 0.69315326 [[-0.00762469]\n",
      " [-0.01111927]]\n",
      "1100 0.69314986 [[-0.00539234]\n",
      " [-0.00725918]]\n",
      "1200 0.6931485 [[-0.00377101]\n",
      " [-0.00476829]]\n",
      "1300 0.6931477 [[-0.00261549]\n",
      " [-0.00314825]]\n",
      "1400 0.6931474 [[-0.00180287]\n",
      " [-0.00208747]]\n",
      "1500 0.6931473 [[-0.00123689]\n",
      " [-0.00138895]]\n",
      "1600 0.6931472 [[-0.00084557]\n",
      " [-0.00092682]]\n",
      "1700 0.6931472 [[-0.00057646]\n",
      " [-0.00061987]]\n",
      "1800 0.6931472 [[-0.00039214]\n",
      " [-0.00041533]]\n",
      "1900 0.6931472 [[-0.00026634]\n",
      " [-0.00027874]]\n",
      "2000 0.6931472 [[-0.00018064]\n",
      " [-0.00018727]]\n",
      "2100 0.6931472 [[-0.00012239]\n",
      " [-0.00012593]]\n",
      "2200 0.6931472 [[-8.286274e-05]\n",
      " [-8.474579e-05]]\n",
      "2300 0.6931472 [[-5.6059991e-05]\n",
      " [-5.7066896e-05]]\n",
      "2400 0.6931472 [[-3.7905913e-05]\n",
      " [-3.8440448e-05]]\n",
      "2500 0.6931472 [[-2.5619902e-05]\n",
      " [-2.5905591e-05]]\n",
      "2600 0.6931472 [[-1.7309530e-05]\n",
      " [-1.7467066e-05]]\n",
      "2700 0.6931472 [[-1.16902975e-05]\n",
      " [-1.17673744e-05]]\n",
      "2800 0.6931472 [[-7.894976e-06]\n",
      " [-7.936290e-06]]\n",
      "2900 0.6931472 [[-5.333468e-06]\n",
      " [-5.349448e-06]]\n",
      "3000 0.6931472 [[-3.5945018e-06]\n",
      " [-3.6015435e-06]]\n",
      "3100 0.6931472 [[-2.4262517e-06]\n",
      " [-2.4288236e-06]]\n",
      "3200 0.6931472 [[-1.6186049e-06]\n",
      " [-1.6196865e-06]]\n",
      "3300 0.6931472 [[-1.1253726e-06]\n",
      " [-1.1264542e-06]]\n",
      "3400 0.6931472 [[-7.3794052e-07]\n",
      " [-7.3753205e-07]]\n",
      "3500 0.6931472 [[-4.905813e-07]\n",
      " [-4.901728e-07]]\n",
      "3600 0.6931472 [[-3.0133592e-07]\n",
      " [-3.0092744e-07]]\n",
      "3700 0.6931472 [[-2.1490885e-07]\n",
      " [-2.1450037e-07]]\n",
      "3800 0.6931472 [[-1.6573483e-07]\n",
      " [-1.6532636e-07]]\n",
      "3900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4100 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4200 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4300 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4400 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4500 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4600 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4700 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4800 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "4900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5100 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5200 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5300 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5400 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5500 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5600 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5700 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5800 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "5900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6100 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6200 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6300 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6400 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6500 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6600 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6700 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6800 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "6900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7100 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7200 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7300 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7400 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7500 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7600 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7700 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7800 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "7900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8100 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8200 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8300 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8400 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8500 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8600 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8700 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8800 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "8900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9100 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9200 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9300 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9400 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9500 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9600 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9700 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9800 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "9900 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n",
      "10000 0.6931472 [[-1.2252130e-07]\n",
      " [-1.2211282e-07]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77508690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc7f79",
   "metadata": {},
   "source": [
    "# Neural Net 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6f7de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db0f7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0], [0,1], [1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ebe83e",
   "metadata": {},
   "source": [
    "###### W부분의 input 값 수정 가능\n",
    "- 2,2로 하더라도 정확도는 1로 수렴\n",
    "- 2,10으로 할 경우에도 정확도는 1에 수렴하고 hypothesis가 더 정밀하게 반응\n",
    "- layer를 늘릴려면 layer층을 계속 쌓으면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b19ea989",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 10]), name = \"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([10]), name = \"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9dee5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([10, 1]), name = \"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), name = \"bias2\")\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bae17309",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "885f43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d536193",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caa9e906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.89230037 [[1.5952512]\n",
      " [1.1695778]]\n",
      "100 0.67863864 [[1.5952512]\n",
      " [1.1695778]]\n",
      "200 0.65787166 [[1.5952512]\n",
      " [1.1695778]]\n",
      "300 0.63431054 [[1.5952512]\n",
      " [1.1695778]]\n",
      "400 0.60591406 [[1.5952512]\n",
      " [1.1695778]]\n",
      "500 0.571344 [[1.5952512]\n",
      " [1.1695778]]\n",
      "600 0.5300708 [[1.5952512]\n",
      " [1.1695778]]\n",
      "700 0.48281533 [[1.5952512]\n",
      " [1.1695778]]\n",
      "800 0.43175074 [[1.5952512]\n",
      " [1.1695778]]\n",
      "900 0.38003284 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1000 0.33080602 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1100 0.28632188 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1200 0.2476373 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1300 0.21482737 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1400 0.18738444 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1500 0.16456033 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1600 0.1455791 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1700 0.12973824 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1800 0.11644413 [[1.5952512]\n",
      " [1.1695778]]\n",
      "1900 0.10521178 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2000 0.09565296 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2100 0.08745864 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2200 0.08038367 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2300 0.07423301 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2400 0.06885083 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2500 0.06411225 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2600 0.05991625 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2700 0.05618073 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2800 0.05283837 [[1.5952512]\n",
      " [1.1695778]]\n",
      "2900 0.049833924 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3000 0.04712137 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3100 0.044662476 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3200 0.042424954 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3300 0.04038173 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3400 0.03850983 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3500 0.036789358 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3600 0.035203643 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3700 0.033738084 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3800 0.03238015 [[1.5952512]\n",
      " [1.1695778]]\n",
      "3900 0.031118749 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4000 0.029944487 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4100 0.02884889 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4200 0.02782472 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4300 0.026865423 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4400 0.025965206 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4500 0.025119063 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4600 0.024322385 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4700 0.023571057 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4800 0.0228615 [[1.5952512]\n",
      " [1.1695778]]\n",
      "4900 0.022190476 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5000 0.021554945 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5100 0.02095235 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5200 0.020380173 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5300 0.019836351 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5400 0.019318856 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5500 0.018825818 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5600 0.018355647 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5700 0.017906884 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5800 0.017478097 [[1.5952512]\n",
      " [1.1695778]]\n",
      "5900 0.017067954 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6000 0.016675431 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6100 0.016299333 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6200 0.015938736 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6300 0.015592741 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6400 0.01526048 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6500 0.014941185 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6600 0.014634114 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6700 0.014338634 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6800 0.014054069 [[1.5952512]\n",
      " [1.1695778]]\n",
      "6900 0.0137798935 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7000 0.0135155255 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7100 0.013260456 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7200 0.01301427 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7300 0.012776475 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7400 0.0125466455 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7500 0.012324439 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7600 0.012109505 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7700 0.011901447 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7800 0.0117000155 [[1.5952512]\n",
      " [1.1695778]]\n",
      "7900 0.0115048615 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8000 0.011315678 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8100 0.011132297 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8200 0.010954337 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8300 0.010781689 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8400 0.010614003 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8500 0.010451186 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8600 0.010292997 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8700 0.010139204 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8800 0.00998967 [[1.5952512]\n",
      " [1.1695778]]\n",
      "8900 0.009844199 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9000 0.0097026955 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9100 0.009564905 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9200 0.009430763 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9300 0.009300134 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9400 0.00917279 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9500 0.00904873 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9600 0.008927772 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9700 0.0088098245 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9800 0.00869475 [[1.5952512]\n",
      " [1.1695778]]\n",
      "9900 0.0085825045 [[1.5952512]\n",
      " [1.1695778]]\n",
      "10000 0.008472919 [[1.5952512]\n",
      " [1.1695778]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4481d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[0.00461893]\n",
      " [0.9894721 ]\n",
      " [0.9930674 ]\n",
      " [0.01165312]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e0941",
   "metadata": {},
   "source": [
    "# tensorboard 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59fbaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72f82bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d3dfb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    W1 = tf.Variable(tf.random_normal([2,2]), name = \"weight1\")\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name = \"bias1\")\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6d512b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81526b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef36b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_SUMMARY_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f4185d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(TB_SUMMARY_DIR)\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f79382f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, _ = sess.run([summary, train], feed_dict = feed_dict)\n",
    "# writer.add_summary(s, global_step = global_step)\n",
    "# global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "57a9dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"./logs/xor_logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32083914",
   "metadata": {},
   "source": [
    "# softmax classification\n",
    "- sigmoid 함수 값이 여러개 생겨서 만들어진 함수를 softmax 함수라고 생각하면됨\n",
    "- classification 되어 있는 각각의 값을 모두 더한 값이 1이되고 그 중 가장 높은 값을 정답 데이터로 하여 추출해내는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae996cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\since\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd65d4d",
   "metadata": {},
   "source": [
    "###### softmax의 경우 onehot 인코딩을 통해서 정답 데이터 값을 만들어줌(y_data의 경우 3개의 값을 가지고 각각 포함될 경우 1의 값을 얻게 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d22bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]]\n",
    "y_data = [[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0], [1,0,0],[1,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c4f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb41a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9949f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd8fa18",
   "metadata": {},
   "source": [
    "### softmax의 cost 값 해석\n",
    "- 여러개의 sigmoid함수를 사용하고 있는 함수이므로 cost(loss) 값을 구할 때 모든 hypothesis를 더하여 나타내준 값의 평균이 cost가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92a26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb20838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e89f820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.4971895\n",
      "200 0.5702657\n",
      "400 0.46471596\n",
      "600 0.38669544\n",
      "800 0.3141119\n",
      "1000 0.24607968\n",
      "1200 0.22071692\n",
      "1400 0.2010678\n",
      "1600 0.18453386\n",
      "1800 0.17043114\n",
      "2000 0.1582658\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45076b31",
   "metadata": {},
   "source": [
    "# one_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b24bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817353e",
   "metadata": {},
   "source": [
    "###### tf.arg_max는 값 중 제일 큰 값을 출력해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4889a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0946802e-03 9.9389511e-01 1.0242175e-05]] [1]\n"
     ]
    }
   ],
   "source": [
    "a = sess.run(hypothesis, feed_dict={X: [[1,11,7,9]]})\n",
    "print(a, sess.run(tf.arg_max(a,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "212ee316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0946830e-03 9.9389511e-01 1.0242185e-05]\n",
      " [8.4885556e-01 1.3628161e-01 1.4862840e-02]\n",
      " [1.6046489e-08 3.7650237e-04 9.9962342e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "all = sess.run(hypothesis, feed_dict={X: [[1,11,7,9],[1,3,4,3,],[1,1,0,1]]})\n",
    "print(all, sess.run(tf.arg_max(all,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97746",
   "metadata": {},
   "source": [
    "# softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf902ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d949b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,2,3], [1,2,6,1], [1,2,5,6], [4,1,3,2], [4,2,2,5], [4,1,5,5], [1,6,6,6], [1,6,6,6]]\n",
    "y_data = [[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0], [1,0,0],[1,0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de33079",
   "metadata": {},
   "source": [
    "# 핵심 X 값은 float로 처리하고 Y 값은 onehot 할 경우 int 처리해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e8b5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.int32, [None, 3])\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522402e1",
   "metadata": {},
   "source": [
    "###### one_hot(Y,nb_classes)  one_hot encoding //  tf.reshape(Y_one_hot, [-1, nb_classes]) 입력 값은 reshape해주고 output은 정답 데이터 개수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f183e53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_one_hot = tf.one_hot(Y,nb_classes)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd4c3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ff5f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16851f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea07f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\since\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels = Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bed9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acef0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f570c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:     0\tLoss: 7.868546\tAcc: 0.375000\n",
      "step:   100\tLoss: 0.090684\tAcc: 1.000000\n",
      "step:   200\tLoss: 0.061842\tAcc: 1.000000\n",
      "step:   300\tLoss: 0.047623\tAcc: 1.000000\n",
      "step:   400\tLoss: 0.038814\tAcc: 1.000000\n",
      "step:   500\tLoss: 0.032761\tAcc: 1.000000\n",
      "step:   600\tLoss: 0.028335\tAcc: 1.000000\n",
      "step:   700\tLoss: 0.024954\tAcc: 1.000000\n",
      "step:   800\tLoss: 0.022288\tAcc: 1.000000\n",
      "step:   900\tLoss: 0.020131\tAcc: 1.000000\n",
      "step:  1000\tLoss: 0.018351\tAcc: 1.000000\n",
      "step:  1100\tLoss: 0.016858\tAcc: 1.000000\n",
      "step:  1200\tLoss: 0.015587\tAcc: 1.000000\n",
      "step:  1300\tLoss: 0.014493\tAcc: 1.000000\n",
      "step:  1400\tLoss: 0.013541\tAcc: 1.000000\n",
      "step:  1500\tLoss: 0.012705\tAcc: 1.000000\n",
      "step:  1600\tLoss: 0.011966\tAcc: 1.000000\n",
      "step:  1700\tLoss: 0.011307\tAcc: 1.000000\n",
      "step:  1800\tLoss: 0.010717\tAcc: 1.000000\n",
      "step:  1900\tLoss: 0.010185\tAcc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(2000):\n",
    "    sess.run(optimizer, feed_dict={X: x_data, Y_one_hot: y_data})\n",
    "    if step % 100 == 0:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={X: x_data, Y_one_hot: y_data})\n",
    "        print(\"step: {:5}\\tLoss: {:3f}\\tAcc: {:2f}\".format(step, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f66e5",
   "metadata": {},
   "source": [
    "# flatten을 통해서 값 생성이 어려워 코드 변경으로 flatten 효과를 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5031a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_data_flatten = []\n",
    "for data in y_data:\n",
    "    data = np.array(data, dtype=\"int64\")\n",
    "    data = np.argmax(data)\n",
    "    y_data_flatten.append(data)\n",
    "y_data_flatten = np.array(y_data_flatten, dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98d474c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True] prediction: 2 True Y: 2\n",
      "[True] prediction: 2 True Y: 2\n",
      "[True] prediction: 2 True Y: 2\n",
      "[True] prediction: 1 True Y: 1\n",
      "[True] prediction: 1 True Y: 1\n",
      "[True] prediction: 1 True Y: 1\n",
      "[True] prediction: 0 True Y: 0\n",
      "[True] prediction: 0 True Y: 0\n"
     ]
    }
   ],
   "source": [
    "pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "for p, y in zip (pred, y_data_flatten):\n",
    "    print(\"[{}] prediction: {} True Y: {}\".format(p == y, p, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852ae7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

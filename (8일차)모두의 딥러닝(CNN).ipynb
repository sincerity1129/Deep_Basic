{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b84774c",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks(CNN) 개념\n",
    "- (conv - relu - conv - relu - pool) 하나의 구조로 이루어져 있고 이 구조를 여러번 반복한 다음 FC(fulling Networks)로 분류하는 구조\n",
    "- conv란 전체 픽셀에서 일부 픽셀 값만 불러서 가져오는 것을 convolution이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3961b",
   "metadata": {},
   "source": [
    "# 32 * 32 * 3의 image가 있다고 가정\n",
    "- 이미지의 일부의 픽셀 값을 처리하는 과정을 filter하며 역할은 일부 픽셀의 값을 정의함\n",
    "- conv란 수 많은 X1W1 + X2W2 + X3W3 + .... + XnWn이 모인 값을 의미함\n",
    "- 수 많은 수식을 합하여 공식화 하면 hypothesis = tf.matmul(X, W) + b와 같은 conv가 만들어진다고 볼 수 있음(3일차 binary 부분 참조)\n",
    "- relu((W * hypothesis) + b)를 하는 것으로 conv한 값을 단순히 relu에 넣어주는 것을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c29cb",
   "metadata": {},
   "source": [
    "# 실제로 CNN 활용 시 W 등 설정 하는 방식(7 * 7 사이즈 이미지 예시)\n",
    "- kernel / stride 값에 따라 수식이 변화될 수 있음\n",
    "- kernel = 3, stride = 2 -> (input - kernel) / stride + 1 = (7-3)/2 + 1 = 3\n",
    "- size가 줄어드는 것을 방지하기 위해 사용하는 것이 padding인데 (kernel - 1)/2를 하면 기존의 image 값을 보존 할 수 있음\n",
    "- 위의 예를 패딩에 적용할 경우 (3-1)/2 = 1의 padding을 주면 됨\n",
    "- padding 했을 경우의 값까지 구하고 싶다면 (input - kernel + 2 * padding) / stride + 1를 하면 padding까지 고려한 output 설정 가능\n",
    "- 따라서 layer층을 만들고 W를 설정할 시에는 kernel 값에 filter을 해주면 됨\n",
    "- 위의 경우 첫번째 W의 경우 (3 * 3) 부분 추출 범위 * 3 RGB * 6 filter = 3*3*3*6 = 162의 값을 넘겨줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82549d9",
   "metadata": {},
   "source": [
    "# 처음 CNN 나왔을 당시의 공식( 5 * 5 stride = 1 -> 2 * 2 stride =2 반복)\n",
    "- 32 * 32 이미지를 5 * 5에 stride = 1를 주고 filter = 6를 주어 적용\n",
    "- 28 * 28(5*5 stride = 1 이므로 (32-5)/1 + 1 = 28)\n",
    "- 28 * 28 이미지를 2 * 2에 stride =2를 주고 filter = 6를 주어 적용\n",
    "- 14 * 14(2*2 stride = 2 이므로 (28-2)2 + 1 = 14)\n",
    "- 14 * 14 이미지를 5 * 5에 stride =1를 주고 filter = 16를 주어 적용\n",
    "- 10 * 10(5*5 stride = 1 이므로 (14-5)1 + 1 = 10)\n",
    "- 10 * 10 이미지를 2 * 2에 stride =2를 주고 filter = 6를 주어 적용\n",
    "- 5 * 5(2*2 stride = 2 이므로 (10-2)2 + 1 = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1a7ba",
   "metadata": {},
   "source": [
    "# CNN 수정(Alex Net - 전체 구조)\n",
    "- 세부사항(relu 처음 사용 / dropout = 0.5 / batch_size =128 / 동일한 networks 7개를 ensemble 하여 실행)\n",
    "\n",
    "\n",
    "- 227 * 227 이미지를 11 * 11에 stride = 4를 주고 filter = 96를 주어 적용\n",
    "- 55 * 55(11*11 stride = 4  이므로 (227-11)/4 + 1 = 55)\n",
    "- 55 * 55 이미지를 3 * 3에 stride = 2를 주고 filter = 96를 주어 maxpool적용\n",
    "- 27 * 27(3*3 stride = 2 이므로 (55-3)/2 +1 = 27)\n",
    "- 27 * 27(Normalization하여 오차 역전파을 평준화 해줌)\n",
    "\n",
    "- 27 * 27 이미지를 5 * 5에 stride = 1, padding = 2, filter = 256를 주어 적용\n",
    "- 27 * 27(5*5 stride=1, padding=2 이므로 (27-5+2*2)1+1= 27)\n",
    "- 27 * 27 이미지를 3 * 3에 stride = 2를 주고 filter = 256를 주어 maxpool적용\n",
    "- 13 * 13(3*3 stride=2, padding=2 이므로 (27-3)2+1= 13)\n",
    "- 13 * 13(Normalization하여 오차 역전파을 평준화 해줌)\n",
    "\n",
    "- 13 * 13 이미지를 3 * 3에 stride = 1, padding = 1, filter = 384를 주어 적용\n",
    "- 13 * 13(3*3 stride=1, padding=1 이므로 (13-3+2*1)1+1= 13)\n",
    "- 13 * 13 이미지를 3 * 3에 stride = 1, padding = 1, filter = 384를 주어 적용\n",
    "- 13 * 13(3*3 stride=1, padding=1 이므로 (13-3+2*1)1+1= 13)\n",
    "- 13 * 13 이미지를 3 * 3에 stride = 1, padding = 1, filter = 256를 주어 적용\n",
    "- 13 * 13(3*3 stride=1, padding=1 이므로 (13-3+2*1)1+1= 13)\n",
    "- 13 * 13 이미지를 3 * 3에 stride =2를 주고 filter = 256을 주어 maxpool 적용\n",
    "- 6 * 6((3*3 stride = 2 이므로 (13-3)/2 +1 = 6)\n",
    "- FC6: 4096 neurons\n",
    "- FC7: 4096 neurons\n",
    "- FC8: 1000 neurons(class scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40bf7c",
   "metadata": {},
   "source": [
    "# 모델 학습 과정에서 layer층이 늘어날 경우 대응 방안\n",
    "- ResNet의 경우 기존 AlexNet(layer=8), googleNet(layer=19)에 비해 비약적인 152개의 layer층으로 구성되어 있음\n",
    "- 이럴 경우 학습하는 과정이 너무 길어지기 때문에 fastforword라는 개념을 활용하여 layer층들을 더하여 구성\n",
    "- fastforword란 일부 layer층에 가중치를 전달하는 것을 건너띄고 다음 layer층과 함께 가중치를 합하여 표현하는 방식\n",
    "- layer층이 많지만 실질적으로는 layer층이 건너띄는 layer층 만큼 줄어드는 효과가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92621e9c",
   "metadata": {},
   "source": [
    "# CNN 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a712db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\since\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9f7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbadc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1d519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "image[0]: batch_size\n",
      "image[1]: image_width\n",
      "image[2]: image_height\n",
      "image[3]: image_color\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "print(\"image[0]: {}\\nimage[1]: {}\\nimage[2]: {}\\nimage[3]: {}\\n\".format\n",
    "      (\"batch_size\", \"image_width\", \"image_height\", \"image_color\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a40aa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e80285eb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANqElEQVR4nO3df6jd9X3H8edrGkWsI7poTWNaWwiTTuiaXVI7x8hYLRqEFFpG/KOKDC6KQgv1j1Ch/Wuw7Y/CXIpZoFKFovvD1oYtXWelTPuHzhgSY7SuiRO8JphqTVRaqHHv/XG/bpfrubn3fs73nnOSPh9wON8fn/N9v/0or3zP93y/JlWFJC3X7427AUlnJsNDUhPDQ1ITw0NSE8NDUhPDQ1KTc4f5cJJLgH8GrgReBv6qqt4cMO5l4G3gPeBUVU0NU1fS+A175rEdeKyqNgCPdesL+Yuq+mODQzo7DBseW4H7u+X7gS8MeTxJZ4gMc4dpkhNVtXrO+ptVdfGAcf8NvAkU8E9Vtes0x5wGpgEuvPDCP7nqqqua+zvbvffee+NuYeK9++67425hor366qu8+eabafnsotc8kvwEuHzArruXUefaqjqa5DLg0SQ/r6rHBw3sgmUXwNTUVO3du3cZZX63nDhxYtwtTLzXXntt3C1MtC9+8YvNn100PKrqcwvtS/JakrVVdSzJWuD4Asc42r0fT/IDYBMwMDwknRmGveaxG7ilW74F+OH8AUkuTHLR+8vA54HnhqwracyGDY+/Ba5L8gvgum6dJB9Jsqcb82HgZ0kOAP8J/GtV/duQdSWN2VD3eVTVG8BfDth+FNjSLb8EfGqYOpImj3eYSmpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIatJLeCS5PsmLSQ4n2T5gf5Lc0+1/NsnGPupKGp+hwyPJOcC3gRuATwI3JfnkvGE3ABu61zRw77B1JY1XH2cem4DDVfVSVf0WeAjYOm/MVuCBmvUksDrJ2h5qSxqTPsJjHfDKnPWZbttyx0g6g/QRHhmwrRrGzA5MppPsTbL3l7/85dDNSVoZfYTHDLB+zvoVwNGGMQBU1a6qmqqqqUsvvbSH9iSthD7C42lgQ5KPJzkP2AbsnjdmN3Bz96vLNcDJqjrWQ21JY3LusAeoqlNJ7gR+DJwD3FdVh5Lc1u3fCewBtgCHgV8Dtw5bV9J4DR0eAFW1h9mAmLtt55zlAu7oo5akyeAdppKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKa9BIeSa5P8mKSw0m2D9i/OcnJJPu71zf6qCtpfM4d9gBJzgG+DVwHzABPJ9ldVc/PG/pEVd04bD1Jk6GPM49NwOGqeqmqfgs8BGzt4biSJtjQZx7AOuCVOeszwGcGjPtskgPAUeCuqjo06GBJpoFpgMsuu4zHHnushxbPTi+++OK4W5h4R44cGXcLE+31119v/mwfZx4ZsK3mre8DPlZVnwL+EXhkoYNV1a6qmqqqqdWrV/fQnqSV0Ed4zADr56xfwezZxf+pqreq6p1ueQ+wKsmaHmpLGpM+wuNpYEOSjyc5D9gG7J47IMnlSdItb+rqvtFDbUljMvQ1j6o6leRO4MfAOcB9VXUoyW3d/p3Al4Dbk5wCfgNsq6r5X20knUH6uGD6/leRPfO27ZyzvAPY0UctSZPBO0wlNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ16SU8ktyX5HiS5xbYnyT3JDmc5NkkG/uoK2l8+jrz+C5w/Wn23wBs6F7TwL091ZU0Jr2ER1U9DvzqNEO2Ag/UrCeB1UnW9lFb0niM6prHOuCVOesz3bYPSDKdZG+SvSdOnBhFb5IajCo8MmBbDRpYVbuqaqqqplavXr2yXUlqNqrwmAHWz1m/Ajg6otqSVsCowmM3cHP3q8s1wMmqOjai2pJWwLl9HCTJg8BmYE2SGeCbwCqAqtoJ7AG2AIeBXwO39lFX0vj0Eh5VddMi+wu4o49akiaDd5hKamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhq0kt4JLkvyfEkzy2wf3OSk0n2d69v9FFX0vj08hddA98FdgAPnGbME1V1Y0/1JI1ZL2ceVfU48Ks+jiXpzNDXmcdSfDbJAeAocFdVHRo0KMk0MA1wwQUXsGPHjhG2eGY5ePDguFuYeEeOHBl3C2etUYXHPuBjVfVOki3AI8CGQQOrahewC+Diiy+uEfUnaZlG8mtLVb1VVe90y3uAVUnWjKK2pJUxkvBIcnmSdMuburpvjKK2pJXRy9eWJA8Cm4E1SWaAbwKrAKpqJ/Al4PYkp4DfANuqyq8k0hmsl/CoqpsW2b+D2Z9yJZ0lvMNUUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSk6HDI8n6JD9N8kKSQ0m+MmBMktyT5HCSZ5NsHLaupPHq4y+6PgV8rar2JbkIeCbJo1X1/JwxNwAbutdngHu7d0lnqKHPPKrqWFXt65bfBl4A1s0bthV4oGY9CaxOsnbY2pLGp9drHkmuBD4NPDVv1zrglTnrM3wwYCSdQfr42gJAkg8BDwNfraq35u8e8JFa4DjTwDTABRdc0Fd7knrWy5lHklXMBsf3qur7A4bMAOvnrF8BHB10rKraVVVTVTV1/vnn99GepBXQx68tAb4DvFBV31pg2G7g5u5Xl2uAk1V1bNjaksanj68t1wJfBg4m2d9t+zrwUYCq2gnsAbYAh4FfA7f2UFfSGA0dHlX1MwZf05g7poA7hq0laXJ4h6mkJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJkOHR5L1SX6a5IUkh5J8ZcCYzUlOJtnfvb4xbF1J43VuD8c4BXytqvYluQh4JsmjVfX8vHFPVNWNPdSTNAGGPvOoqmNVta9bfht4AVg37HElTbZUVX8HS64EHgeurqq35mzfDDwMzABHgbuq6tACx5gGprvVq4HnemtweGuA18fdxBz2s7hJ62nS+vnDqrqo5YO9hUeSDwH/AfxNVX1/3r7fB/6nqt5JsgX4h6rasIRj7q2qqV4a7IH9nN6k9QOT19PZ1E8vv7YkWcXsmcX35gcHQFW9VVXvdMt7gFVJ1vRRW9J49PFrS4DvAC9U1bcWGHN5N44km7q6bwxbW9L49PFry7XAl4GDSfZ3274OfBSgqnYCXwJuT3IK+A2wrZb2fWlXD/31yX5Ob9L6gcnr6azpp9cLppJ+d3iHqaQmhoekJhMTHkkuSfJokl907xcvMO7lJAe729z3rkAf1yd5McnhJNsH7E+Se7r9zybZ2HcPDT2N7Pb/JPclOZ5k4P03Y5qfxXoa6eMRS3xkY2TztGKPkFTVRLyAvwe2d8vbgb9bYNzLwJoV6uEc4AjwCeA84ADwyXljtgA/AgJcAzy1wvOylJ42A/8yon9Pfw5sBJ5bYP9I52eJPY1sfrp6a4GN3fJFwH+N87+jJfaz7DmamDMPYCtwf7d8P/CFMfSwCThcVS9V1W+Bh7q+5toKPFCzngRWJ1k75p5GpqoeB351miGjnp+l9DRStbRHNkY2T0vsZ9kmKTw+XFXHYPYfFrhsgXEF/HuSZ7pb2fu0DnhlzvoMH5zkpYwZdU8An01yIMmPkvzRCvazmFHPz1KNZX66RzY+DTw1b9dY5uk0/cAy56iP+zyWLMlPgMsH7Lp7GYe5tqqOJrkMeDTJz7s/efqQAdvm/5a9lDF9Wkq9fcDH6v9v/38EWPT2/xUy6vlZirHMT/fIxsPAV2vOs17v7x7wkRWdp0X6WfYcjfTMo6o+V1VXD3j9EHjt/dO27v34Asc42r0fB37A7Gl9X2aA9XPWr2D2Qb7ljunTovVqsm7/H/X8LGoc87PYIxuMeJ5W4hGSSfrashu4pVu+Bfjh/AFJLszs/zOEJBcCn6ffp26fBjYk+XiS84BtXV/z+7y5u1p+DXDy/a9bK2TRnjJZt/+Pen4WNer56Wqd9pENRjhPS+mnaY5W8qrzMq8I/wHwGPCL7v2SbvtHgD3d8ieY/bXhAHAIuHsF+tjC7NXoI+8fH7gNuK1bDvDtbv9BYGoEc7NYT3d283EAeBL40xXs5UHgGPAus396/vUEzM9iPY1sfrp6f8bsV5Bngf3da8u45mmJ/Sx7jrw9XVKTSfraIukMYnhIamJ4SGpieEhqYnhIamJ4SGpieEhq8r+pTw4icY2ilQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape(3,3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf9572",
   "metadata": {},
   "source": [
    "###### weight = (2,2,1,1)로 주는데 앞의 2,2는 kernel 값이고 다음 1은 RGB 그리고 마지막 1은 stride를 의미\n",
    "- padding = same(image와 동일한 size) / valid(image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ab364ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "#weight = tf.constant([[[[1.]], [[1.]]],[[[1.]],[[1.]]]])\n",
    "weight_filter3 = tf.constant([[[[1., 10, -1]], [[1., 10, -1]]],[[[1., 10, -1]],[[1., 10, -1]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "# padding 값 다르게 주기 (same/valid)\n",
    "# w 값 filter 다르게 주기\n",
    "conv2d = tf.nn.conv2d(image, weight_filter3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    #padding에 따라 reshpae가 달라짐 - same(3,3) / valid(2,2)\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "320916bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[[[4],[3]],[[2],[1]]]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4fdb60",
   "metadata": {},
   "source": [
    "###### padding은 동일하고 각각의 값 4, 3, 2, 1  값 중에서 가장 큰 값을 pool해오므로 아래와 같이 4, 3, 2, 1의 값을 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f7a48ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(image, ksize=[1,2,2,1],strides=[1,1,1,1], padding=\"SAME\")\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
